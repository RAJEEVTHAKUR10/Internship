{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c46bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c3e1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activeting the chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dbe81a",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ef39f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7dbe9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01775fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0b2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b052a6",
   "metadata": {},
   "source": [
    "2. Scrape the details team India‚Äôs international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5f8eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting the url with driver\n",
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on international match\n",
    "international = driver.find_element_by_xpath('//li[@class=\"nav-item ml-0\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "116b903e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>9 JUN 2022</td>\n",
       "      <td>&lt;module 'time' (built-in)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Barabati Stadium,</td>\n",
       "      <td>12 JUN 2022</td>\n",
       "      <td>&lt;module 'time' (built-in)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,</td>\n",
       "      <td>14 JUN 2022</td>\n",
       "      <td>&lt;module 'time' (built-in)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>17 JUN 2022</td>\n",
       "      <td>&lt;module 'time' (built-in)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>19 JUN 2022</td>\n",
       "      <td>&lt;module 'time' (built-in)&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_title                                      Series  \\\n",
       "0          NaN  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "1          NaN  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "2          NaN  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "3          NaN  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "4          NaN  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "\n",
       "                                               Place         Date  \\\n",
       "0                              Arun Jaitley Stadium,   9 JUN 2022   \n",
       "1                                  Barabati Stadium,  12 JUN 2022   \n",
       "2  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,  14 JUN 2022   \n",
       "3            Saurashtra Cricket Association Stadium,  17 JUN 2022   \n",
       "4                             M Chinnaswamy Stadium,  19 JUN 2022   \n",
       "\n",
       "                         Time  \n",
       "0  <module 'time' (built-in)>  \n",
       "1  <module 'time' (built-in)>  \n",
       "2  <module 'time' (built-in)>  \n",
       "3  <module 'time' (built-in)>  \n",
       "4  <module 'time' (built-in)>  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty list\n",
    "match_ti = []\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "times = []\n",
    "\n",
    "# use for loop\n",
    "match_t = driver.find_elements_by_xpath('//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in match_t:\n",
    "    match_ti.append(i.text)   \n",
    "time.sleep(6)\n",
    "\n",
    "series_tag = driver.find_elements_by_xpath('//span[@class=\"ng-binding\"]')\n",
    "for i in series_tag:\n",
    "    series.append(i.text)\n",
    "time.sleep(3)\n",
    "\n",
    "place_tags = driver.find_elements_by_xpath('//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in place_tags:\n",
    "    place.append(i.text)\n",
    "time.sleep(3)    \n",
    "    \n",
    "date_tags = driver.find_elements_by_xpath('//h5[@class=\"ng-binding\"]')\n",
    "for i in date_tags:\n",
    "    date.append(i.text)\n",
    "time.sleep(3)    \n",
    "    \n",
    "time_tags = driver.find_elements_by_xpath('//h5[@class=\"text-right ng-binding\"]')\n",
    "for i in time_tags:\n",
    "    times.append(i.text)\n",
    "time.sleep(3)\n",
    "\n",
    "# Make DataFrame\n",
    "data = pd.DataFrame({})\n",
    "data['Match_title'] = match_ti\n",
    "data['Series'] = series\n",
    "data['Place'] = place\n",
    "data['Date'] =date\n",
    "data['Time'] =time\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49292c",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e05742d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.guru99.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036878fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b54f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac55cde2",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fca4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the url with driver\n",
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea77e7ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=101.0.4951.54)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AFB8F3+2406643]\n\tOrdinal0 [0x00A8AF31+1945393]\n\tOrdinal0 [0x0097C610+837136]\n\tOrdinal0 [0x009AA2D3+1024723]\n\tOrdinal0 [0x009A0083+983171]\n\tOrdinal0 [0x009C427C+1131132]\n\tOrdinal0 [0x0099FA64+981604]\n\tOrdinal0 [0x009C4494+1131668]\n\tOrdinal0 [0x009D4682+1197698]\n\tOrdinal0 [0x009C4096+1130646]\n\tOrdinal0 [0x0099E636+976438]\n\tOrdinal0 [0x0099F546+980294]\n\tGetHandleVerifier [0x00D69612+2498066]\n\tGetHandleVerifier [0x00D5C920+2445600]\n\tGetHandleVerifier [0x00B94F2A+579370]\n\tGetHandleVerifier [0x00B93D36+574774]\n\tOrdinal0 [0x00A91C0B+1973259]\n\tOrdinal0 [0x00A96688+1992328]\n\tOrdinal0 [0x00A96775+1992565]\n\tOrdinal0 [0x00A9F8D1+2029777]\n\tBaseThreadInitThunk [0x7630FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D77A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D77A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-184c276bc14b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# click on india\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mindia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    708\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=101.0.4951.54)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AFB8F3+2406643]\n\tOrdinal0 [0x00A8AF31+1945393]\n\tOrdinal0 [0x0097C610+837136]\n\tOrdinal0 [0x009AA2D3+1024723]\n\tOrdinal0 [0x009A0083+983171]\n\tOrdinal0 [0x009C427C+1131132]\n\tOrdinal0 [0x0099FA64+981604]\n\tOrdinal0 [0x009C4494+1131668]\n\tOrdinal0 [0x009D4682+1197698]\n\tOrdinal0 [0x009C4096+1130646]\n\tOrdinal0 [0x0099E636+976438]\n\tOrdinal0 [0x0099F546+980294]\n\tGetHandleVerifier [0x00D69612+2498066]\n\tGetHandleVerifier [0x00D5C920+2445600]\n\tGetHandleVerifier [0x00B94F2A+579370]\n\tGetHandleVerifier [0x00B93D36+574774]\n\tOrdinal0 [0x00A91C0B+1973259]\n\tOrdinal0 [0x00A96688+1992328]\n\tOrdinal0 [0x00A96775+1992565]\n\tOrdinal0 [0x00A9F8D1+2029777]\n\tBaseThreadInitThunk [0x7630FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D77A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D77A6E+238]\n"
     ]
    }
   ],
   "source": [
    "# click on economy\n",
    "economy = driver.find_element_by_xpath('//button[@class=\"dropbtn\"]').click()\n",
    "time.sleep(3)\n",
    "# click on india\n",
    "india = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# close ads\n",
    "try:\n",
    "    ad = driver.find_element_by_xpath('/html/body/div/div/div[1]/div[1]').click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# click on gdp of india\n",
    "#gdp = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "\n",
    "# Extract all tags\n",
    "rank_tag = driver.find_elements_by_xpath('//td[@class=\"data1\"]')\n",
    "state_tag = driver.find_elements_by_xpath('//td[@class=\"name\"]')\n",
    "gsdp_tag = driver.find_elements_by_xpath('//td[@class=\"data sorting_1\"]')\n",
    "gdp_billion_tag = driver.find_elements_by_xpath('//td[@class=\"data\"]')\n",
    "\n",
    "\n",
    "# make empty list\n",
    "rank = []\n",
    "state =[]\n",
    "gsdp =[]\n",
    "gdp_billion = []\n",
    "\n",
    "# use for loop\n",
    "for i in rank_tag:\n",
    "    rank.append(i.text)\n",
    "for i in state_tag:\n",
    "    state.append(i.text)\n",
    "for i in gsdp_tag:\n",
    "    if i is None:\n",
    "        gsdp.append('--')\n",
    "    else:\n",
    "        gsdp.append(i.text)\n",
    "for i in gdp_billion_tag:\n",
    "    gdp_billion.append(i.text)\n",
    "\n",
    "# Make dataframe\n",
    "data = pd.DataFrame({}) \n",
    "data['Rank'] =rank [0:66]\n",
    "data['State'] = state[0:66]\n",
    "data['GSDP(18-19)'] = gsdp[0:66]\n",
    "data['GDP_BILLION'] =  gdp_billion[0:66]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec22af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91911f38",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "ASSIGNMENT\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37ef08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting the url with chromedriver\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "007cff0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebookresearch / metaseq</td>\n",
       "      <td>Repo for external large-scale work</td>\n",
       "      <td>1,463</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>education / GitHubGraduation-2022</td>\n",
       "      <td>Join the GitHub Graduation Yearbook and \"walk ...</td>\n",
       "      <td>111</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freeCodeCamp / freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>404</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scottbez1 / smartknob</td>\n",
       "      <td>Haptic input knob with software-defined endsto...</td>\n",
       "      <td>2,793</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft / PowerToys</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>345,410</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pyscript / pyscript</td>\n",
       "      <td>This repo contain the syllabus of the Hugging ...</td>\n",
       "      <td>28,591</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>huggingface / deep-rl-class</td>\n",
       "      <td>Repository containing the game data for the ga...</td>\n",
       "      <td>9,011</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dimbreath / GenshinData</td>\n",
       "      <td>Digital Forensics Guide</td>\n",
       "      <td>452</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mikeroyal / Digital-Forensics-Guide</td>\n",
       "      <td>A server software reimplementation for a certa...</td>\n",
       "      <td>72,461</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grasscutters / Grasscutter</td>\n",
       "      <td>12 weeks, 26 lessons, 52 quizzes, classic Mach...</td>\n",
       "      <td>4,094</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>microsoft / ML-For-Beginners</td>\n",
       "      <td>The Modern Data Stack üê∞ ‚Äî Directus is an insta...</td>\n",
       "      <td>6,203</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>directus / directus</td>\n",
       "      <td>Python notebooks with ML and deep learning exa...</td>\n",
       "      <td>340</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Azure / MachineLearningNotebooks</td>\n",
       "      <td>üéÆ Refer√™ncias para Game Designers.</td>\n",
       "      <td>735</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>baptixta / game-design-refs</td>\n",
       "      <td>üìö ÂÖçË¥πÁöÑËÆ°ÁÆóÊú∫ÁºñÁ®ãÁ±ª‰∏≠Êñá‰π¶Á±çÔºåÊ¨¢ËøéÊäïÁ®ø</td>\n",
       "      <td>59</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>justjavac / free-programming-books-zh_CN</td>\n",
       "      <td>This repository contains .NET Documentation.</td>\n",
       "      <td>900</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dotnet / docs</td>\n",
       "      <td>A layer 1 for everyone!</td>\n",
       "      <td>323</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aptos-labs / aptos-core</td>\n",
       "      <td>SteamOS 3 (Holo) archiso configuration</td>\n",
       "      <td>191</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bhaiest / holoiso</td>\n",
       "      <td>Docker container for managing Nginx proxy host...</td>\n",
       "      <td>16</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NginxProxyManager / nginx-proxy-manager</td>\n",
       "      <td>Azure Quickstart Templates</td>\n",
       "      <td>4,517</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Azure / azure-quickstart-templates</td>\n",
       "      <td>CVNets: A library for training computer vision...</td>\n",
       "      <td>1,708</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  \\\n",
       "0                 facebookresearch / metaseq   \n",
       "1          education / GitHubGraduation-2022   \n",
       "2                freeCodeCamp / freeCodeCamp   \n",
       "3                      scottbez1 / smartknob   \n",
       "4                      microsoft / PowerToys   \n",
       "5                        pyscript / pyscript   \n",
       "6                huggingface / deep-rl-class   \n",
       "7                    Dimbreath / GenshinData   \n",
       "8        mikeroyal / Digital-Forensics-Guide   \n",
       "9                 Grasscutters / Grasscutter   \n",
       "10              microsoft / ML-For-Beginners   \n",
       "11                       directus / directus   \n",
       "12          Azure / MachineLearningNotebooks   \n",
       "13               baptixta / game-design-refs   \n",
       "14  justjavac / free-programming-books-zh_CN   \n",
       "15                             dotnet / docs   \n",
       "16                   aptos-labs / aptos-core   \n",
       "17                         bhaiest / holoiso   \n",
       "18   NginxProxyManager / nginx-proxy-manager   \n",
       "19        Azure / azure-quickstart-templates   \n",
       "\n",
       "                                          Description Contributors  \\\n",
       "0                  Repo for external large-scale work        1,463   \n",
       "1   Join the GitHub Graduation Yearbook and \"walk ...          111   \n",
       "2   freeCodeCamp.org's open-source codebase and cu...          404   \n",
       "3   Haptic input knob with software-defined endsto...        2,793   \n",
       "4   Windows system utilities to maximize productivity      345,410   \n",
       "5   This repo contain the syllabus of the Hugging ...       28,591   \n",
       "6   Repository containing the game data for the ga...        9,011   \n",
       "7                             Digital Forensics Guide          452   \n",
       "8   A server software reimplementation for a certa...       72,461   \n",
       "9   12 weeks, 26 lessons, 52 quizzes, classic Mach...        4,094   \n",
       "10  The Modern Data Stack üê∞ ‚Äî Directus is an insta...        6,203   \n",
       "11  Python notebooks with ML and deep learning exa...          340   \n",
       "12                 üéÆ Refer√™ncias para Game Designers.          735   \n",
       "13                               üìö ÂÖçË¥πÁöÑËÆ°ÁÆóÊú∫ÁºñÁ®ãÁ±ª‰∏≠Êñá‰π¶Á±çÔºåÊ¨¢ËøéÊäïÁ®ø           59   \n",
       "14       This repository contains .NET Documentation.          900   \n",
       "15                            A layer 1 for everyone!          323   \n",
       "16             SteamOS 3 (Holo) archiso configuration          191   \n",
       "17  Docker container for managing Nginx proxy host...           16   \n",
       "18                         Azure Quickstart Templates        4,517   \n",
       "19  CVNets: A library for training computer vision...        1,708   \n",
       "\n",
       "            Language  \n",
       "0             Python  \n",
       "1         JavaScript  \n",
       "2         TypeScript  \n",
       "3                C++  \n",
       "4                 C#  \n",
       "5         JavaScript  \n",
       "6   Jupyter Notebook  \n",
       "7             Python  \n",
       "8               Java  \n",
       "9   Jupyter Notebook  \n",
       "10        TypeScript  \n",
       "11  Jupyter Notebook  \n",
       "12              Rust  \n",
       "13             Shell  \n",
       "14        JavaScript  \n",
       "15             Shell  \n",
       "16                C#  \n",
       "17            Python  \n",
       "18        JavaScript  \n",
       "19               PHP  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make empty list\n",
    "title = []\n",
    "description =[]\n",
    "contributors =[]\n",
    "language =[]\n",
    "\n",
    "# clicking on explore tab\n",
    "explore = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary').click()\n",
    "time.sleep(3)\n",
    "# clicking on trending tab\n",
    "trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# extracting all tabs\n",
    "title_tag = driver.find_elements_by_xpath('//h1[@class=\"h3 lh-condensed\"]')\n",
    "description_tag =driver.find_elements_by_xpath('//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "contributors_tag =driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]')\n",
    "language_tag = driver.find_elements_by_xpath('//span[@itemprop=\"programmingLanguage\"]')\n",
    "\n",
    "# using for loop\n",
    "for i in title_tag:\n",
    "    title.append(i.text)\n",
    "for i in description_tag:\n",
    "    if i.text is None:\n",
    "        description.append('--')\n",
    "    else:\n",
    "        description.append(i.text)\n",
    "for i in contributors_tag:\n",
    "    contributors.append(i.text)\n",
    "for i in language_tag:\n",
    "    language.append(i.text)\n",
    "\n",
    "#Make DataFrame\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title [0:20]\n",
    "data['Description'] = description [0:20]\n",
    "data['Contributors'] = contributors [0:20]\n",
    "data['Language'] = language[0:20]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c01a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7240de90",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14d02122",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.billboard.com/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking the hot 100\n",
    "hot_100 = driver.find_element_by_xpath('//a[@class=\"c-link  lrv-a-unstyle-link lrv-u-color-brand-primary:hover lrv-a-hover-effect lrv-u-whitespace-nowrap lrv-u-color-grey-dark\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be9b8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the empty lists\n",
    "song_name = []\n",
    "artist_name = []\n",
    "last_week_rank = []\n",
    "peak_rank =[]\n",
    "weeks=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3acd3c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First Class</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big Energy</td>\n",
       "      <td>Latto</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enemy</td>\n",
       "      <td>Imagine Dragons X JID</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bones</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hate Our Love</td>\n",
       "      <td>Queen Naija &amp; Big Sean</td>\n",
       "      <td>94</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Over</td>\n",
       "      <td>Lucky Daye</td>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>City Of Gods</td>\n",
       "      <td>Fivio Foreign, Kanye West &amp; Alicia Keys</td>\n",
       "      <td>84</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Brambleton</td>\n",
       "      <td>Pusha T</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song_name                              Artist_name Last_week_rank  \\\n",
       "0       As It Was                             Harry Styles              1   \n",
       "1     First Class                              Jack Harlow              2   \n",
       "2      Heat Waves                            Glass Animals              3   \n",
       "3      Big Energy                                    Latto              4   \n",
       "4           Enemy                    Imagine Dragons X JID              5   \n",
       "..            ...                                      ...            ...   \n",
       "95          Bones                          Imagine Dragons             87   \n",
       "96  Hate Our Love                   Queen Naija & Big Sean             94   \n",
       "97           Over                               Lucky Daye             92   \n",
       "98   City Of Gods  Fivio Foreign, Kanye West & Alicia Keys             84   \n",
       "99     Brambleton                                  Pusha T              -   \n",
       "\n",
       "   Peak_rank Weeks  \n",
       "0          1     4  \n",
       "1          1     3  \n",
       "2          1    67  \n",
       "3          3    27  \n",
       "4          5    23  \n",
       "..       ...   ...  \n",
       "95        87     7  \n",
       "96        88     3  \n",
       "97        77     6  \n",
       "98        46    10  \n",
       "99       100     1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the song name\n",
    "song_tag = driver.find_elements_by_id(\"title-of-a-story\")\n",
    "for i in song_tag:\n",
    "    song_name.append(i.text)\n",
    "song_name = song_name[6:403:4]\n",
    "\n",
    "# Scrape the artist name\n",
    "artist_tag1 = driver.find_elements_by_xpath('//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "artist_tag2 = driver.find_elements_by_xpath('//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in artist_tag1:\n",
    "    artist_name.append(i.text)\n",
    "for i in artist_tag2:\n",
    "    artist_name.append(i.text)\n",
    "    \n",
    "# Scrape the last_week_rank   \n",
    "last_week = driver.find_elements_by_xpath('//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]')\n",
    "for i in last_week:\n",
    "    last_week_rank.append(i.text)\n",
    "last_week_rank = last_week_rank[0:200:2]\n",
    "\n",
    "# Scrape the peak_rank\n",
    "peak_rank_tag =driver.find_elements_by_xpath('//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]')\n",
    "for i in peak_rank_tag:\n",
    "    peak_rank.append(i.text)\n",
    "peak_rank = peak_rank[1:200:2]\n",
    "\n",
    "# Scrape the weeks on board\n",
    "weeks_on_board_tag =driver.find_elements_by_xpath('//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]')\n",
    "for i in weeks_on_board_tag:\n",
    "    weeks.append(i.text)\n",
    "weeks = weeks[1:200:2]\n",
    "\n",
    "# make the DataFrame\n",
    "data = pd.DataFrame({'Song_name':song_name,\n",
    "                     'Artist_name':artist_name,\n",
    "                     'Last_week_rank':last_week_rank,\n",
    "                     'Peak_rank':peak_rank,'Weeks':weeks})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0faa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3e8ae46",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0f4ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This url connect with Chrome server\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# Searching the job of Data Science\n",
    "search = driver.find_element_by_xpath('//input[@class=\"suggestor-input \"]')\n",
    "search.send_keys('Data Science')\n",
    "# clicking the search button\n",
    "search.btn = driver.find_element_by_xpath('//div[@class=\"qsbSubmit\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c642d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make empty lists\n",
    "name = []\n",
    "designation =[]\n",
    "company = []\n",
    "skill = []\n",
    "location = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "259c8d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst- Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Please note this role may require you to work ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior AI Scientist - SAP Procurement Data Sci...</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>SummaryThe SAP Procurement Data Science Team s...</td>\n",
       "      <td>Predictive Modeling</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Scientist - SAP Procurement Data Science Team</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>Candidates with a bachelor s degree should hav...</td>\n",
       "      <td>data models</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Science Analyst</td>\n",
       "      <td>Everi India</td>\n",
       "      <td>Azure (or cloud) are all highly preferredAdvan...</td>\n",
       "      <td>data mining</td>\n",
       "      <td>Hyderabad/Secunderabad, Mangaluru/Mangalore, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCL || Data Science</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Role: Data Science / Data Analytics Qualificat...</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI Developer - SAP Procurement Data Science Team</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>SummaryThe SAP Procurement Data Science Team s...</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Associate Manager</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>BS in data science, computer science or a rela...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Team Lead/Consultant-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Please note this role may require you to work ...</td>\n",
       "      <td>IT Skills</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Manager (NLP/NLG) MLOps Azure Dat...</td>\n",
       "      <td>Hexaware Technologies</td>\n",
       "      <td>Cloud ML experience in Azure Experience in imp...</td>\n",
       "      <td>Java</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Team Lead / Consultant - Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Skill required: Data Science - Data Visualizat...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Science Analyst 2</td>\n",
       "      <td>AllianceData</td>\n",
       "      <td>Job Summary Under supervision and guidance, th...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Opening For Manager / Sr. Manager Data Science</td>\n",
       "      <td>MSD Pharmaceuticals</td>\n",
       "      <td>A unique opportunity to be part of an Insight ...</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Science &amp; Analytics</td>\n",
       "      <td>MORE RETAIL LIMITED</td>\n",
       "      <td>2 years of experience</td>\n",
       "      <td>SAP</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Senior Analyst - Data Science</td>\n",
       "      <td>Tiger Analytics India LLP</td>\n",
       "      <td>B Tech from Tier-1 college / MS or M Tech is p...</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Team Lead/Consultant-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Job DescriptionSkill required: Data Science - ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Team Lead/Consultant-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Please note this role may require you to work ...</td>\n",
       "      <td>IT Skills</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>QualificationsEducational Background/qualifica...</td>\n",
       "      <td>Java</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Engineer - PDE (Deep Learning,Data Science,IIOT)</td>\n",
       "      <td>Micron Tech</td>\n",
       "      <td>Job Description SummaryAs PDE PCS/Metro/Proces...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lead - Data Science</td>\n",
       "      <td>Think360</td>\n",
       "      <td>Experience of team handling, and client manage...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science/Data scientist| Product Company|5...</td>\n",
       "      <td>HighRadius</td>\n",
       "      <td>Should have at least 5+ years of experience wo...</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>Bhubaneswar, Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0                               Analyst- Data Science   \n",
       "1   Senior AI Scientist - SAP Procurement Data Sci...   \n",
       "2    AI Scientist - SAP Procurement Data Science Team   \n",
       "3                         Senior Data Science Analyst   \n",
       "4                                 HCL || Data Science   \n",
       "5    AI Developer - SAP Procurement Data Science Team   \n",
       "6                      Data Science Associate Manager   \n",
       "7                   Team Lead/Consultant-Data Science   \n",
       "8   Data Science Manager (NLP/NLG) MLOps Azure Dat...   \n",
       "9               Team Lead / Consultant - Data Science   \n",
       "10                             Data Science Analyst 2   \n",
       "11     Opening For Manager / Sr. Manager Data Science   \n",
       "12                           Data Science & Analytics   \n",
       "13                      Senior Analyst - Data Science   \n",
       "14                  Team Lead/Consultant-Data Science   \n",
       "15                  Team Lead/Consultant-Data Science   \n",
       "16  ACN - Applied Intelligence - CC - Data Science...   \n",
       "17   Engineer - PDE (Deep Learning,Data Science,IIOT)   \n",
       "18                                Lead - Data Science   \n",
       "19  Data Science/Data scientist| Product Company|5...   \n",
       "\n",
       "                      Company  \\\n",
       "0                   Accenture   \n",
       "1           SAP India Pvt.Ltd   \n",
       "2           SAP India Pvt.Ltd   \n",
       "3                 Everi India   \n",
       "4            HCL Technologies   \n",
       "5           SAP India Pvt.Ltd   \n",
       "6                   Accenture   \n",
       "7                   Accenture   \n",
       "8       Hexaware Technologies   \n",
       "9                   Accenture   \n",
       "10               AllianceData   \n",
       "11        MSD Pharmaceuticals   \n",
       "12        MORE RETAIL LIMITED   \n",
       "13  Tiger Analytics India LLP   \n",
       "14                  Accenture   \n",
       "15                  Accenture   \n",
       "16                  Accenture   \n",
       "17                Micron Tech   \n",
       "18                   Think360   \n",
       "19                 HighRadius   \n",
       "\n",
       "                                          Designation                Skill  \\\n",
       "0   Please note this role may require you to work ...         Data Science   \n",
       "1   SummaryThe SAP Procurement Data Science Team s...  Predictive Modeling   \n",
       "2   Candidates with a bachelor s degree should hav...          data models   \n",
       "3   Azure (or cloud) are all highly preferredAdvan...          data mining   \n",
       "4   Role: Data Science / Data Analytics Qualificat...     machine learning   \n",
       "5   SummaryThe SAP Procurement Data Science Team s...            Analytics   \n",
       "6   BS in data science, computer science or a rela...               Python   \n",
       "7   Please note this role may require you to work ...            IT Skills   \n",
       "8   Cloud ML experience in Azure Experience in imp...                 Java   \n",
       "9   Skill required: Data Science - Data Visualizat...         Data Science   \n",
       "10  Job Summary Under supervision and guidance, th...     Machine Learning   \n",
       "11  A unique opportunity to be part of an Insight ...                Cloud   \n",
       "12                              2 years of experience                  SAP   \n",
       "13  B Tech from Tier-1 college / MS or M Tech is p...          Procurement   \n",
       "14  Job DescriptionSkill required: Data Science - ...               Python   \n",
       "15  Please note this role may require you to work ...            IT Skills   \n",
       "16  QualificationsEducational Background/qualifica...                 Java   \n",
       "17  Job Description SummaryAs PDE PCS/Metro/Proces...         Data Science   \n",
       "18  Experience of team handling, and client manage...     Machine Learning   \n",
       "19  Should have at least 5+ years of experience wo...                Cloud   \n",
       "\n",
       "                                             Location  \n",
       "0                                 Bangalore/Bengaluru  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3   Hyderabad/Secunderabad, Mangaluru/Mangalore, C...  \n",
       "4           Chennai, Bangalore/Bengaluru, Delhi / NCR  \n",
       "5                                 Bangalore/Bengaluru  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8    Chennai, Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "9                                 Bangalore/Bengaluru  \n",
       "10                                Bangalore/Bengaluru  \n",
       "11                                               Pune  \n",
       "12                                Bangalore/Bengaluru  \n",
       "13                                            Chennai  \n",
       "14                                             Mumbai  \n",
       "15                                             Mumbai  \n",
       "16                                   Gurgaon/Gurugram  \n",
       "17                             Hyderabad/Secunderabad  \n",
       "18                                             Mumbai  \n",
       "19                Bhubaneswar, Hyderabad/Secunderabad  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the job name\n",
    "name_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in name_tag:\n",
    "    if i.text is None :\n",
    "        name.append('--')\n",
    "    else:\n",
    "        name.append(i.text)\n",
    "        \n",
    "# scrape the designation\n",
    "designation_tag = driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]')\n",
    "for i in designation_tag:\n",
    "    if i.text is None:\n",
    "        designation.append(\"--\")\n",
    "    else:\n",
    "        designation.append(i.text)\n",
    "        \n",
    "# Scrape the company name     \n",
    "company_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag:\n",
    "    if i.text is None :\n",
    "        company.append('--')\n",
    "    else:\n",
    "        company.append(i.text)\n",
    "\n",
    "# Scrape the skill        \n",
    "skill_tag = driver.find_elements_by_xpath('//li[@class=\"fleft fs12 grey-text lh16 dot\"]')\n",
    "for i in skill_tag:\n",
    "    if i.text is None:\n",
    "        skill.append(\"--\")\n",
    "    else:\n",
    "        skill.append(i.text)\n",
    "\n",
    "# Scrape the locations        \n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        location.append(\"--\")\n",
    "    else:\n",
    "        location.append(i.text)\n",
    "        \n",
    "# Make the DataFrame\n",
    "data = pd.DataFrame()\n",
    "data['Name'] = name\n",
    "data['Company'] = company\n",
    "data['Designation'] = designation\n",
    "data['Skill'] = skill [0:20]\n",
    "data['Location'] =location\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcefb268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "449f2e7b",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1fd22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey%02compare/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f2509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb77ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42165042",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcca7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "# Make empty lists\n",
    "name = []\n",
    "year_span = []\n",
    "genre = []\n",
    "run_time = []\n",
    "rating = []\n",
    "votes = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1db35a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1981258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>986971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>944193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>282093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>241987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013‚Äì2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017‚Äì2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>59194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005‚Äì2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>188887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream</td>\n",
       "      <td>(2015‚Äì2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>226451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span  \\\n",
       "0                  Game of Thrones  (2011‚Äì2019)   \n",
       "1                  Stranger Things     (2016‚Äì )   \n",
       "2                 The Walking Dead  (2010‚Äì2022)   \n",
       "3                   13 Reasons Why  (2017‚Äì2020)   \n",
       "4                          The 100  (2014‚Äì2020)   \n",
       "..                             ...          ...   \n",
       "95                           Reign  (2013‚Äì2017)   \n",
       "96  A Series of Unfortunate Events  (2017‚Äì2019)   \n",
       "97                  Criminal Minds  (2005‚Äì2020)   \n",
       "98                          Scream  (2015‚Äì2019)   \n",
       "99      The Haunting of Hill House       (2018)   \n",
       "\n",
       "                                   Genre Run_time  Rating    Votes  \n",
       "0   Action, Adventure, Drama               57 min     9.2  1981258  \n",
       "1     Drama, Fantasy, Horror               51 min     8.7   986971  \n",
       "2    Drama, Horror, Thriller               44 min     8.2   944193  \n",
       "3   Drama, Mystery, Thriller               60 min     7.5   282093  \n",
       "4     Drama, Mystery, Sci-Fi               43 min     7.6   241987  \n",
       "..                                   ...      ...     ...      ...  \n",
       "95            Drama, Fantasy               42 min     7.4    48560  \n",
       "96  Adventure, Comedy, Drama               50 min     7.8    59194  \n",
       "97     Crime, Drama, Mystery               42 min     8.1   188887  \n",
       "98      Comedy, Crime, Drama               45 min     7.1    40032  \n",
       "99    Drama, Horror, Mystery              572 min     8.6   226451  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Movies Name\n",
    "movie_name = soup.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "for i in movie_name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        name.append(j.text)\n",
    "\n",
    "# Scrape the year Span\n",
    "year = soup.find_all('span',class_=\"lister-item-year text-muted unbold\")\n",
    "for i in year:\n",
    "    year_span.append(i.text)\n",
    "\n",
    "# Scrape the Genre\n",
    "genre_tag = soup.find_all('span',class_=\"genre\")\n",
    "for i in genre_tag:\n",
    "    genre.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "# Scrape the Run Time\n",
    "run_time_tag = soup.find_all('span',class_=\"runtime\")\n",
    "for i in run_time_tag:\n",
    "    run_time.append(i.text)\n",
    "    \n",
    "# Scrape the Rating\n",
    "rating_tag = soup.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "for i in rating_tag:\n",
    "      rating.append(float(i.text))\n",
    "    \n",
    "# Scrapie the Votes\n",
    "votes_tag= soup.find_all('span', attrs={'name':'nv'})\n",
    "for i in votes_tag:\n",
    "    votes.append(i['data-value'])\n",
    "    \n",
    "# Make the DataFrame\n",
    "imdb_list = pd.DataFrame ({'Name':name,\n",
    "              'Year_span':year_span,\n",
    "              'Genre':genre,\n",
    "              'Run_time':run_time,\n",
    "              'Rating':rating ,\n",
    "              'Votes':votes})\n",
    "imdb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304d8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cb81b5c",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6db3c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activeting the chrome brower\n",
    "url = 'https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6021aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on view all data sets\n",
    "all_dataset = driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4552a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make empty lists\n",
    "dataset = []\n",
    "datatype = []\n",
    "task =[]\n",
    "attribute_type =[]\n",
    "no_of_instances =[]\n",
    "no_of_attribute =[]\n",
    "year =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a23fe07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Datatype</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Dataset  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                       Datatype                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the Dataset name\n",
    "dataset_tags =driver.find_elements_by_xpath('//p[@class=\"normal\"]')\n",
    "for i in dataset_tags:\n",
    "    dataset.append(i.text)\n",
    "dataset = dataset[8:4362:7]\n",
    "\n",
    "# Scrape the Data Types\n",
    "datatypes = driver.find_elements_by_xpath('//p[@class=\"normal\"]')\n",
    "for i in datatypes:\n",
    "    datatype.append(i.text)\n",
    "datatype = datatype[9:4362:7]\n",
    "\n",
    "# Scrape the Task\n",
    "task_tags =driver.find_elements_by_xpath('//p[@class=\"normal\"]')\n",
    "for i in task_tags:\n",
    "    task.append(i.text)\n",
    "task = task[10:5985:7]\n",
    "\n",
    "# Scrape the Attribute Type\n",
    "attribute_type_tag = driver.find_elements_by_xpath('//p[@class=\"normal\"]')\n",
    "for i in attribute_type_tag:\n",
    "    attribute_type.append(i.text)\n",
    "attribute_type = attribute_type[11:5985:7]\n",
    "\n",
    "# Scrape the No of instances\n",
    "no_of_instances_tag = driver.find_elements_by_xpath('//p[@class=\"normal\"]')\n",
    "for i in no_of_instances_tag:\n",
    "    no_of_instances.append(i.text)\n",
    "no_of_instances = no_of_instances[12:5985:7]\n",
    "\n",
    "# Scrape the No of attribute\n",
    "no_of_attribute_tag = driver.find_elements_by_xpath('//p[@class=\"normal\"]')\n",
    "for i in no_of_attribute_tag:\n",
    "    no_of_attribute.append(i.text)\n",
    "no_of_attribute = no_of_attribute[13:5985:7]\n",
    "\n",
    "# Scrape the Year\n",
    "year_tag = driver.find_elements_by_xpath('//p[@class=\"normal\"]')\n",
    "for i in year_tag:\n",
    "    year.append(i.text)\n",
    "year = year[14:5985:7]\n",
    "\n",
    "# Make the data frame\n",
    "data = pd.DataFrame({'Dataset':dataset,\n",
    "                     'Datatype':datatype,\n",
    "                     'Task':task ,\n",
    "                     'Attribute_type':attribute_type,\n",
    "                     'No_of_instances':no_of_instances,\n",
    "                     'No_of_attribute':no_of_attribute,\n",
    "                     'Year':year})\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fe682ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 622, 622, 622, 622, 622, 622)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset),len(datatype),len(task),len(attribute_type),len(no_of_instances),len(no_of_attribute),len(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
