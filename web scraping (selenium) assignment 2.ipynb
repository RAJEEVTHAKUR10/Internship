{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1eed8c",
   "metadata": {},
   "source": [
    "# WEB SCRAPING - ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d980fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bf98945",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258849f",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "724d1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1fb9a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Titles</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Analyst I(SQL &amp; Python)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Clario India Pvt Ltd</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Data Analytics\\nanalytical\\nR\\nSpotfire\\nchain...</td>\n",
       "      <td>1. Should have minimum 1year of hands in exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Computer science\\nadobe analytics\\nAnalytical\\...</td>\n",
       "      <td>Bachelors in Engineering, Computer Science, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Excel\\nPower BI\\nSQL\\ndimensional modelling\\nH...</td>\n",
       "      <td>Along with this, you will be expected to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Data analysis\\nAutomation\\nData modeling\\nAnal...</td>\n",
       "      <td>Able to envision &amp; implement the optimal data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Automation\\nData analysis\\nData modeling\\nData...</td>\n",
       "      <td>Able to envision &amp; implement the optimal data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst - Ads &amp; Promotion Platform...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Data analysis\\nBidding\\nSimulation\\nMachine le...</td>\n",
       "      <td>A Bachelor s degree in any field At least 3 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring Data analyst with Pharma Background acr...</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>HCL</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>data analysis\\npharma\\ndata collection\\nanalyt...</td>\n",
       "      <td>Ability to perform data analysis &amp; hands-on ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Coordinator | Data Analyst | MS Excel | T...</td>\n",
       "      <td>Bangalore/Bengaluru(Sadashiva Nagar)</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>excel\\ndata analysis\\ntyping\\nBPO\\ncustomer se...</td>\n",
       "      <td>Roles and Responsibilities The Customer Servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Analyst - Flipkart Data science group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Business Intelligence\\nBi\\nReporting\\nsql</td>\n",
       "      <td>Along with this, you will be expected to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>python\\nMS Excel\\nMySQL\\nBusiness Intelligence...</td>\n",
       "      <td>DESIRED SKILLSET - Proven working experience a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_Titles  \\\n",
       "0            Hiring For Data Analyst I(SQL & Python)   \n",
       "1                             Senior Data Analyst II   \n",
       "2                                Senior Data Analyst   \n",
       "3                             Senior Data Analyst II   \n",
       "4                             Senior Data Analyst II   \n",
       "5  Senior Data Analyst - Ads & Promotion Platform...   \n",
       "6  Hiring Data analyst with Pharma Background acr...   \n",
       "7  Data Coordinator | Data Analyst | MS Excel | T...   \n",
       "8    Lead Data Analyst - Flipkart Data science group   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "7               Bangalore/Bengaluru(Sadashiva Nagar)   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                      Company Experience  \\\n",
       "0                        Clario India Pvt Ltd    0-2 Yrs   \n",
       "1                                    Flipkart    3-6 Yrs   \n",
       "2                                    Flipkart    3-8 Yrs   \n",
       "3                                    Flipkart    2-4 Yrs   \n",
       "4                                    Flipkart    2-4 Yrs   \n",
       "5                                       Gojek    3-8 Yrs   \n",
       "6                                         HCL   6-11 Yrs   \n",
       "7  Inspiration Manpower Consultancy Pvt. Ltd.    4-7 Yrs   \n",
       "8                                    Flipkart    1-3 Yrs   \n",
       "9                                    Flipkart   7-12 Yrs   \n",
       "\n",
       "                                               Skill  \\\n",
       "0  Data Analytics\\nanalytical\\nR\\nSpotfire\\nchain...   \n",
       "1  Computer science\\nadobe analytics\\nAnalytical\\...   \n",
       "2  Excel\\nPower BI\\nSQL\\ndimensional modelling\\nH...   \n",
       "3  Data analysis\\nAutomation\\nData modeling\\nAnal...   \n",
       "4  Automation\\nData analysis\\nData modeling\\nData...   \n",
       "5  Data analysis\\nBidding\\nSimulation\\nMachine le...   \n",
       "6  data analysis\\npharma\\ndata collection\\nanalyt...   \n",
       "7  excel\\ndata analysis\\ntyping\\nBPO\\ncustomer se...   \n",
       "8          Business Intelligence\\nBi\\nReporting\\nsql   \n",
       "9  python\\nMS Excel\\nMySQL\\nBusiness Intelligence...   \n",
       "\n",
       "                                         Designation  \n",
       "0  1. Should have minimum 1year of hands in exper...  \n",
       "1  Bachelors in Engineering, Computer Science, Ma...  \n",
       "2  Along with this, you will be expected to have ...  \n",
       "3  Able to envision & implement the optimal data ...  \n",
       "4  Able to envision & implement the optimal data ...  \n",
       "5  A Bachelor s degree in any field At least 3 ye...  \n",
       "6  Ability to perform data analysis & hands-on ex...  \n",
       "7  Roles and Responsibilities The Customer Servic...  \n",
       "8  Along with this, you will be expected to have ...  \n",
       "9  DESIRED SKILLSET - Proven working experience a...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding web element using for search job bar using id\n",
    "search_jobs = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "search_jobs\n",
    "\n",
    "# write on search bar\n",
    "search_jobs.send_keys('Data Analyst')\n",
    "\n",
    "# finding web element for search location bar using absolute xpath\n",
    "search_location = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_location.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking using xpath function for search bar button\n",
    "search_btn = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()\n",
    "\n",
    "# let's extract all web elements tags\n",
    "title_tags= driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "locn_tags  = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "company_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "exp_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "skill_tags = driver.find_elements_by_xpath('//ul[@class=\"tags has-description\"]')\n",
    "designation_tags = driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]')\n",
    "\n",
    "\n",
    "job_title = []     #empty list\n",
    "location = []      #empty list\n",
    "company_names = [] #empty list\n",
    "experience = []    #empty list\n",
    "skill = []         #empty list\n",
    "designation = []   #empty list\n",
    "\n",
    "# Using for loop to convert data to text.\n",
    "\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "for i in locn_tags:\n",
    "    location.append(i.text)\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "for i in skill_tags:\n",
    "    skill.append(i.text)\n",
    "for i in designation_tags:\n",
    "    designation.append(i.text)\n",
    "    \n",
    "# Make DataFrame for first 10 rows    \n",
    "\n",
    "Data = pd.DataFrame()\n",
    "Data['Job_Titles'] = job_title[0:10]\n",
    "Data['Location'] = location[0:10]\n",
    "Data['Company'] = company_names[0:10]\n",
    "Data['Experience'] = experience[0:10]\n",
    "Data['Skill'] = skill[0:10]\n",
    "Data['Designation'] = designation[0:10]\n",
    "Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3bdb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3323820a",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79024cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c33b01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Titles</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Unix\\nComputer science\\nVersion control\\nSAS\\n...</td>\n",
       "      <td>work experience with a Bachelor s Degree or 5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Need Data scientists and data engineers - WFH-...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>Covalense Technologies Private Limited</td>\n",
       "      <td>scientist\\ndata engineering\\nPython</td>\n",
       "      <td>Notice (need to join within 10-15 days only)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mobile Premier League</td>\n",
       "      <td>Computer science\\nData analysis\\ndata science\\...</td>\n",
       "      <td>Bachelor s / Master s / PhD degree in Computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>analytics\\npython\\nr\\ncredit risk\\npredictive ...</td>\n",
       "      <td>Experience of 2+ years in Python / R in buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist Payments</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AirSeva</td>\n",
       "      <td>Data Sets\\nSQL Queries\\nHive Databases\\nAirflo...</td>\n",
       "      <td>Proficient in writing and understanding comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Computer Vision Python Data Scientist</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>OceanOfWeb</td>\n",
       "      <td>DL\\nML\\nNatural Language\\ncommunication\\nanaly...</td>\n",
       "      <td>The candidate should have worked on some core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Minions Ventures</td>\n",
       "      <td>Text mining\\nData mining\\nComputer Science\\nMa...</td>\n",
       "      <td>• Use analytical rigor and statistical methods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>Design engineering\\ndata science\\nMachine lear...</td>\n",
       "      <td>Experience working with cross-functional teams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Kyndryl</td>\n",
       "      <td>Unix\\nIT services\\nSAN\\nPerformance tuning\\nMa...</td>\n",
       "      <td>Willingness to work in nights shifts or suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist / Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>open data fabric</td>\n",
       "      <td>Data Science\\nData Analytics\\nPower - BI\\nBig ...</td>\n",
       "      <td>University / college degree in Computer Scienc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_Titles  \\\n",
       "0                                Sr . Data Scientist   \n",
       "1  Need Data scientists and data engineers - WFH-...   \n",
       "2                           Principal Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                     Senior Data Scientist Payments   \n",
       "5              Computer Vision Python Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                Lead Data Scientist   \n",
       "9                           Data Scientist / Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                  Company  \\\n",
       "0                                    Visa   \n",
       "1  Covalense Technologies Private Limited   \n",
       "2                   Mobile Premier League   \n",
       "3                               HDFC Bank   \n",
       "4                                 AirSeva   \n",
       "5                              OceanOfWeb   \n",
       "6                        Minions Ventures   \n",
       "7                                   Gojek   \n",
       "8                                 Kyndryl   \n",
       "9                        open data fabric   \n",
       "\n",
       "                                               Skill  \\\n",
       "0  Unix\\nComputer science\\nVersion control\\nSAS\\n...   \n",
       "1                scientist\\ndata engineering\\nPython   \n",
       "2  Computer science\\nData analysis\\ndata science\\...   \n",
       "3  analytics\\npython\\nr\\ncredit risk\\npredictive ...   \n",
       "4  Data Sets\\nSQL Queries\\nHive Databases\\nAirflo...   \n",
       "5  DL\\nML\\nNatural Language\\ncommunication\\nanaly...   \n",
       "6  Text mining\\nData mining\\nComputer Science\\nMa...   \n",
       "7  Design engineering\\ndata science\\nMachine lear...   \n",
       "8  Unix\\nIT services\\nSAN\\nPerformance tuning\\nMa...   \n",
       "9  Data Science\\nData Analytics\\nPower - BI\\nBig ...   \n",
       "\n",
       "                                         Designation  \n",
       "0  work experience with a Bachelor s Degree or 5 ...  \n",
       "1       Notice (need to join within 10-15 days only)  \n",
       "2  Bachelor s / Master s / PhD degree in Computer...  \n",
       "3  Experience of 2+ years in Python / R in buildi...  \n",
       "4  Proficient in writing and understanding comple...  \n",
       "5  The candidate should have worked on some core ...  \n",
       "6  • Use analytical rigor and statistical methods...  \n",
       "7  Experience working with cross-functional teams...  \n",
       "8  Willingness to work in nights shifts or suppor...  \n",
       "9  University / college degree in Computer Scienc...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding web element using for search job bar using id\n",
    "search_jobs = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "search_jobs\n",
    "\n",
    "# write on search bar\n",
    "search_jobs.send_keys('Data Scientist')\n",
    "\n",
    "# finding web element for search location bar using absolute xpath\n",
    "search_locn = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_locn.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking using xpath function for search bar button\n",
    "search_btn = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()\n",
    "\n",
    "# let's extract all web elements tags\n",
    "title_tags= driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "locn_tags  = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "company_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "skill_tags = driver.find_elements_by_xpath('//ul[@class=\"tags has-description\"]')\n",
    "designation_tags = driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]')\n",
    "\n",
    "\n",
    "job_title = []     #empty list\n",
    "location = []      #empty list\n",
    "company_names = [] #empty list\n",
    "skill = []         #empty list\n",
    "designation = []   #empty list\n",
    "\n",
    "# Using for loop to convert data to text.\n",
    "\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "for i in locn_tags:\n",
    "    location.append(i.text)\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "for i in skill_tags:\n",
    "    skill.append(i.text)\n",
    "for i in designation_tags:\n",
    "    designation.append(i.text)\n",
    "    \n",
    "# Make DataFrame for first 10 rows    \n",
    "\n",
    "Data = pd.DataFrame()\n",
    "Data['Job_Titles'] = job_title[0:10]\n",
    "Data['Location'] = location[0:10]\n",
    "Data['Company'] = company_names[0:10]\n",
    "Data['Skill'] = skill[0:10]\n",
    "Data['Designation'] = designation[0:10]\n",
    "Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1298d0",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79cc16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5be47c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior or Lead Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Cyient</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>IT Skills\\nPython\\nAzure\\nsql queries\\ndata an...</td>\n",
       "      <td>University degree (minimum), ideally in comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Looking For Senior / Lead Data Scientist with ...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Cyient</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Azure Data Factory\\nAzureML\\nData Scientist\\nN...</td>\n",
       "      <td>University degree (minimum), ideally in comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Unix\\nComputer science\\nVersion control\\nSAS\\n...</td>\n",
       "      <td>work experience with a Bachelor s Degree or 5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Need Data scientists and data engineers - WFH-...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>Covalense Technologies Private Limited</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "      <td>scientist\\ndata engineering\\nPython</td>\n",
       "      <td>Notice (need to join within 10-15 days only)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mobile Premier League</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Computer science\\nData analysis\\ndata science\\...</td>\n",
       "      <td>Bachelor s / Master s / PhD degree in Computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>analytics\\npython\\nr\\ncredit risk\\npredictive ...</td>\n",
       "      <td>Experience of 2+ years in Python / R in buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Senior Data Scientist || Noida/Hyde...</td>\n",
       "      <td>Noida, New Delhi, Hyderabad/Secunderabad, Gurg...</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Logistic Regression\\nNeural Networks\\nUnsuperv...</td>\n",
       "      <td>About usTokopedia is an Indonesian unicorn tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Shell</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Functional Analytics\\nmachine learning\\nDecisi...</td>\n",
       "      <td>The RolePurpose &amp; accountabilitiesGeneral Posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead- Data Scientist FMCG/ Retail Analytics</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Vertex Corporate Services</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "      <td>Retail Analytics\\nText Mining\\nmachine learnin...</td>\n",
       "      <td>Position: Lead-Data Scientist FMCG/ Retail Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist/ Data Analyst- Permanent Remote...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Lending Tree Research Services LLP</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>analytics\\nR\\ndata insight\\ndata analysis\\nExc...</td>\n",
       "      <td>Strong in Data analytics: The candidate should...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                      Senior or Lead Data Scientist   \n",
       "1  Looking For Senior / Lead Data Scientist with ...   \n",
       "2                                Sr . Data Scientist   \n",
       "3  Need Data scientists and data engineers - WFH-...   \n",
       "4                           Principal Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6  Hiring For Senior Data Scientist || Noida/Hyde...   \n",
       "7                           Associate Data Scientist   \n",
       "8        Lead- Data Scientist FMCG/ Retail Analytics   \n",
       "9  Data Scientist/ Data Analyst- Permanent Remote...   \n",
       "\n",
       "                                            Location  \\\n",
       "0                             Hyderabad/Secunderabad   \n",
       "1                             Hyderabad/Secunderabad   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...   \n",
       "6  Noida, New Delhi, Hyderabad/Secunderabad, Gurg...   \n",
       "7                                            Chennai   \n",
       "8                                               Pune   \n",
       "9                                             Remote   \n",
       "\n",
       "                             Company_name Experience  \\\n",
       "0                                  Cyient   5-10 Yrs   \n",
       "1                                  Cyient   5-10 Yrs   \n",
       "2                                    Visa    6-8 Yrs   \n",
       "3  Covalense Technologies Private Limited   8-13 Yrs   \n",
       "4                   Mobile Premier League   8-12 Yrs   \n",
       "5                               HDFC Bank    1-6 Yrs   \n",
       "6                               Tokopedia    2-4 Yrs   \n",
       "7                                   Shell    2-7 Yrs   \n",
       "8               Vertex Corporate Services  10-15 Yrs   \n",
       "9      Lending Tree Research Services LLP    1-6 Yrs   \n",
       "\n",
       "                                               Skill  \\\n",
       "0  IT Skills\\nPython\\nAzure\\nsql queries\\ndata an...   \n",
       "1  Azure Data Factory\\nAzureML\\nData Scientist\\nN...   \n",
       "2  Unix\\nComputer science\\nVersion control\\nSAS\\n...   \n",
       "3                scientist\\ndata engineering\\nPython   \n",
       "4  Computer science\\nData analysis\\ndata science\\...   \n",
       "5  analytics\\npython\\nr\\ncredit risk\\npredictive ...   \n",
       "6  Logistic Regression\\nNeural Networks\\nUnsuperv...   \n",
       "7  Functional Analytics\\nmachine learning\\nDecisi...   \n",
       "8  Retail Analytics\\nText Mining\\nmachine learnin...   \n",
       "9  analytics\\nR\\ndata insight\\ndata analysis\\nExc...   \n",
       "\n",
       "                                         Designation  \n",
       "0  University degree (minimum), ideally in comput...  \n",
       "1  University degree (minimum), ideally in comput...  \n",
       "2  work experience with a Bachelor s Degree or 5 ...  \n",
       "3       Notice (need to join within 10-15 days only)  \n",
       "4  Bachelor s / Master s / PhD degree in Computer...  \n",
       "5  Experience of 2+ years in Python / R in buildi...  \n",
       "6  About usTokopedia is an Indonesian unicorn tec...  \n",
       "7  The RolePurpose & accountabilitiesGeneral Posi...  \n",
       "8  Position: Lead-Data Scientist FMCG/ Retail Ana...  \n",
       "9  Strong in Data analytics: The candidate should...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding web element using for search job bar using id\n",
    "search_job = driver.find_element_by_class_name('suggestor-input ')\n",
    "search_job\n",
    "\n",
    "# write on search bar\n",
    "search_job.send_keys('Data Scientist')\n",
    "# clicking using xpath function for search bar button\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()\n",
    "\n",
    "# let's extract all web elements tags\n",
    "job_titles = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "locn_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "company_names = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "exp_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "skill_tags = driver.find_elements_by_xpath('//ul[@class=\"tags has-description\"]')\n",
    "designation_tags= driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]')\n",
    "\n",
    "\n",
    "job_title = []\n",
    "location = []\n",
    "company_name = []\n",
    "exp = []\n",
    "skill = []\n",
    "designation = []\n",
    "\n",
    "\n",
    "for i in job_titles:\n",
    "    job_title.append(i.text)\n",
    "for i in locn_tags:\n",
    "    location.append(i.text)\n",
    "for i in company_names:\n",
    "    company_name.append(i.text)\n",
    "for i in exp_tags:\n",
    "    exp.append(i.text)\n",
    "for i in skill_tags:\n",
    "    skill.append(i.text)\n",
    "for i in designation_tags:\n",
    "    designation.append(i.text)\n",
    "\n",
    "# Make DataFrame for first 10 rows \n",
    "Data = pd.DataFrame()\n",
    "Data['Job_Title'] = job_title [0:10]\n",
    "Data['Location'] = location [0:10]\n",
    "Data['Company_name'] =company_name [0:10]\n",
    "Data['Experience'] = exp [0:10]\n",
    "Data['Skill'] = skill [0:10]\n",
    "Data['Designation'] = designation [0:10]\n",
    "Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a162bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on location filter\n",
    "location_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "313457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on salary filter\n",
    "salary_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6bedde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e43f703",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41d1bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfd0b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the pop up of log in\n",
    "close = driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9287e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding web element using for search product bar using id\n",
    "search_product = driver.find_element_by_class_name('_3704LK')\n",
    "search_product.send_keys('sunglasses')\n",
    "\n",
    "# clicking on search button\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72393f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (55)</td>\n",
       "      <td>₹314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹3,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹6,649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>₹250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                            Product   Price\n",
       "0           PIRASO              UV Protection Cat-eye Sunglasses (55)    ₹314\n",
       "1          Ray-Ban   UV Protection Rectangular Sunglasses (Free Size)  ₹3,479\n",
       "2             SRPM             UV Protection Wayfarer Sunglasses (50)    ₹198\n",
       "3           PIRASO              UV Protection Aviator Sunglasses (54)    ₹229\n",
       "4           SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...    ₹253\n",
       "..             ...                                                ...     ...\n",
       "95         Ray-Ban  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹6,649\n",
       "96          PIRASO         UV Protection Retro Square Sunglasses (53)    ₹250\n",
       "97  kingsunglasses            Mirrored Aviator Sunglasses (Free Size)    ₹184\n",
       "98      Lee Topper  UV Protection Retro Square Sunglasses (Free Size)    ₹199\n",
       "99          PIRASO                   Mirrored Aviator Sunglasses (55)    ₹349\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand = []   # empty list\n",
    "product = [] #empty list\n",
    "price = []   #empty list\n",
    "\n",
    "# using for loop for next page\n",
    "for j in range(4):\n",
    "    # let's extract all web elements tags\n",
    "    brand_tags = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    product_tags = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    price_tags= driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in brand_tags:\n",
    "        brand.append(i.text)\n",
    "    for i in product_tags:\n",
    "        product.append(i.text)\n",
    "    for i in price_tags:\n",
    "        price.append(i.text)\n",
    "    next_btn = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "# Make DataFrame for first 100 rows \n",
    "Data = pd.DataFrame()\n",
    "Data['Brand'] = brand [0:100]\n",
    "Data['Product'] = product [0:100]\n",
    "Data['Price'] =price [0:100]\n",
    "Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4a31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a1cd6dc",
   "metadata": {},
   "source": [
    "5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5989606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYL0BETT&marketplace=FLIPKART'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb0968a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating               Review  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5    Worth every penny   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  i11 is worthy to buy, too much happy with the ...  \n",
       "99  What a camera .....just awesome ..you can feel...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "review = []\n",
    "full_review = []\n",
    "# using for loop for next page\n",
    "for d in range(10):\n",
    "    #let's extract all web elements tags\n",
    "    rating_tags = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    review_tags = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    full_review_tags = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        \n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "    for i in review_tags:\n",
    "        review.append(i.text)\n",
    "    for i in full_review_tags:\n",
    "        full_review.append(i.text)\n",
    "    next_btn = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "# Make DataFrame for first 100 rows\n",
    "data = pd.DataFrame()\n",
    "data['Rating'] = rating [0:100]\n",
    "data['Review'] = review [0:100]\n",
    "data['Full Review'] =full_review\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770622ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07bd0418",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66d28ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6213885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on product in search bar\n",
    "search_product = driver.find_element_by_class_name('_3704LK')\n",
    "search_product.send_keys('sneakers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dda080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search button\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a99ba11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹680</td>\n",
       "      <td>31% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noztile</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹448</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹649</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹341</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Varito</td>\n",
       "      <td>Shark-41 Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Men White Solid Sneakers Sneakers For Men</td>\n",
       "      <td>₹198</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>corsac</td>\n",
       "      <td>Combo Pack Of 2 Latest Stylish Casual Shoes fo...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern &amp; Trendy Collection Combo Pack of 02 Sh...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Casual Trendy Sneaker Casual Shoes For Men Sne...</td>\n",
       "      <td>₹1,299</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                            Product   Price  \\\n",
       "0   RapidBox                                   Sneakers For Men    ₹680   \n",
       "1    Noztile                                   Sneakers For Men    ₹399   \n",
       "2   Magnolia  Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹448   \n",
       "3     Chevit                                   Sneakers For Men    ₹649   \n",
       "4         TR                                   Sneakers For Men    ₹341   \n",
       "..       ...                                                ...     ...   \n",
       "95    Varito                          Shark-41 Sneakers For Men    ₹499   \n",
       "96  URBANBOX          Men White Solid Sneakers Sneakers For Men    ₹198   \n",
       "97    corsac  Combo Pack Of 2 Latest Stylish Casual Shoes fo...    ₹449   \n",
       "98    BRUTON  Modern & Trendy Collection Combo Pack of 02 Sh...    ₹299   \n",
       "99  Roadster  Casual Trendy Sneaker Casual Shoes For Men Sne...  ₹1,299   \n",
       "\n",
       "   Discount  \n",
       "0   31% off  \n",
       "1   80% off  \n",
       "2   55% off  \n",
       "3   59% off  \n",
       "4   65% off  \n",
       "..      ...  \n",
       "95  77% off  \n",
       "96  80% off  \n",
       "97  70% off  \n",
       "98  76% off  \n",
       "99  53% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand = []   # empty list\n",
    "product = [] # empty list\n",
    "price = []   # empty list\n",
    "discount = []# empty list\n",
    "\n",
    "#  using for loop for next page \n",
    "for k in range(3):\n",
    "    # let's extract all web elements tas\n",
    "    brand_tags = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    product_tags = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    price_tags = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    discount_tags = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    \n",
    "    for i in brand_tags:\n",
    "        brand.append(i.text)\n",
    "    for i in product_tags:\n",
    "        product.append(i.text)\n",
    "    for i in price_tags:\n",
    "        price.append(i.text)\n",
    "    for i in discount_tags:\n",
    "        discount.append(i.text)\n",
    "    next_btn = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "      \n",
    "# Make DataFrame for first 100 rows \n",
    "Data = pd.DataFrame()\n",
    "Data['Brand'] = brand [0:100]\n",
    "Data['Product'] = product [0:100]\n",
    "Data['Price'] = price [0:100]\n",
    "Data['Discount'] = discount [0:100]\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84545cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b281a5c5",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image.\n",
    "\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44091749",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d1384c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding web element using for color bar using \n",
    "color = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[1]/label/div')\n",
    "color.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4c153b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on price\n",
    "price = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c67c32ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Shoe_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sole To Soul</td>\n",
       "      <td>High-Top Block Heeled Boots</td>\n",
       "      <td>Rs. 7900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sole To Soul</td>\n",
       "      <td>Women Block Heeled Boots</td>\n",
       "      <td>Rs. 8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sole To Soul</td>\n",
       "      <td>Suede High-Top Block Heeled Boots</td>\n",
       "      <td>Rs. 9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td></td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Balance</td>\n",
       "      <td>Women Woven Running Shoes</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Platform Heeled Boots</td>\n",
       "      <td>Rs. 9265Rs. 10900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Block Heeled Boots with Bows</td>\n",
       "      <td>Rs. 11815Rs. 13900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Suede Party High-Top Block Heeled Boots</td>\n",
       "      <td>Rs. 8925Rs. 10500(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                         Shoe_description  \\\n",
       "0     Sole To Soul              High-Top Block Heeled Boots   \n",
       "1     Sole To Soul                 Women Block Heeled Boots   \n",
       "2     Sole To Soul        Suede High-Top Block Heeled Boots   \n",
       "3   ROSSO BRUNELLO                                            \n",
       "4      New Balance                Women Woven Running Shoes   \n",
       "..             ...                                      ...   \n",
       "95         Saint G            Leather Platform Heeled Boots   \n",
       "96         Saint G     Leather Block Heeled Boots with Bows   \n",
       "97        DAVINCHI      Men Textured Formal Leather Loafers   \n",
       "98         Saint G  Suede Party High-Top Block Heeled Boots   \n",
       "99        DAVINCHI          Men Solid Leather Formal Derbys   \n",
       "\n",
       "                          Price  \n",
       "0                      Rs. 7900  \n",
       "1                      Rs. 8900  \n",
       "2                      Rs. 9500  \n",
       "3                      Rs. 8499  \n",
       "4    Rs. 7799Rs. 12999(40% OFF)  \n",
       "..                          ...  \n",
       "95   Rs. 9265Rs. 10900(15% OFF)  \n",
       "96  Rs. 11815Rs. 13900(15% OFF)  \n",
       "97                     Rs. 8990  \n",
       "98   Rs. 8925Rs. 10500(15% OFF)  \n",
       "99                     Rs. 9990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand = []            # empty list\n",
    "Shoe_description = [] # empty list\n",
    "price = []            # empty list\n",
    "\n",
    "# using for loop for next page \n",
    "for j in range(2):\n",
    "    # let's extract all web elements tags\n",
    "    brand_tags = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    Shoe_description_tags = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    price_tags = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for i in brand_tags:\n",
    "        brand.append(i.text)\n",
    "    for i in Shoe_description_tags:\n",
    "        Shoe_description.append(i.text)\n",
    "    for i in price_tags:\n",
    "        price.append(i.text)\n",
    "    next_btn = driver.find_element_by_xpath('//A[@rel=\"next\"]').click()\n",
    "# Make DataFrame for first 100 rows \n",
    "Data = pd.DataFrame()\n",
    "Data['Brand'] = brand [0:100]\n",
    "Data['Shoe_description'] = Shoe_description [0:100]\n",
    "Data['Price'] = price [0:100]\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de1c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1148757f",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes.\n",
    "\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6652a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3132c7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td>901</td>\n",
       "      <td>₹77,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram 16 Ultra-Light Intel Evo 11th Gen Core...</td>\n",
       "      <td>84</td>\n",
       "      <td>₹85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>21</td>\n",
       "      <td>₹57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td>901</td>\n",
       "      <td>₹77,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>75</td>\n",
       "      <td>₹91,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F17 (2022), 17.3-inch (43.94 c...</td>\n",
       "      <td>44</td>\n",
       "      <td>₹1,35,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Microsoft Surface Studio 14.4 inches Touchscre...</td>\n",
       "      <td>3</td>\n",
       "      <td>₹3,73,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>37</td>\n",
       "      <td>₹89,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Acer Nitro 5 11th Gen Intel Core i5-...</td>\n",
       "      <td>9</td>\n",
       "      <td>₹62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...</td>\n",
       "      <td>2</td>\n",
       "      <td>₹87,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating      price\n",
       "0  Mi Notebook Ultra 3.2K Resolution Display Inte...    901    ₹77,499\n",
       "1  LG Gram 16 Ultra-Light Intel Evo 11th Gen Core...     84    ₹85,990\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...     21    ₹57,490\n",
       "3  Mi Notebook Ultra 3.2K Resolution Display Inte...    901    ₹77,499\n",
       "4  HP Pavilion x360 11th Gen Intel Core i7 14 inc...     75    ₹91,800\n",
       "5  ASUS TUF Gaming F17 (2022), 17.3-inch (43.94 c...     44  ₹1,35,990\n",
       "6  Microsoft Surface Studio 14.4 inches Touchscre...      3  ₹3,73,999\n",
       "7  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...     37    ₹89,490\n",
       "8  (Renewed) Acer Nitro 5 11th Gen Intel Core i5-...      9    ₹62,990\n",
       "9  Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...      2    ₹87,990"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write on product in search bar\n",
    "search_product = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search_product.send_keys('Laptop')\n",
    "# click on search bar button\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_btn.click()\n",
    "\n",
    "# select cpu \n",
    "cpu = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[5]/li[11]/span/a/div/label/i')\n",
    "cpu.click()\n",
    "\n",
    "# let's extract all web elements tags\n",
    "title_tags = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "rating_tags = driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]')\n",
    "price_tags = driver.find_elements_by_xpath('//span[@class=\"a-price\"]')\n",
    "\n",
    "title = []  # empty list\n",
    "rating = [] # empty list\n",
    "price = []  # empty list\n",
    "# used for loop\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "for i in rating_tags:\n",
    "    rating.append(i.text)\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "# Make DataFrame for first 10 rows \n",
    "Data = pd.DataFrame()\n",
    "Data['Title'] = title [0:10]\n",
    "Data['Rating'] = rating [0:10]\n",
    "Data['price'] =price [0:10]\n",
    "Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e233774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93304329",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3db6d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4fc8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of click on jobs\n",
    "job_btn = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]').click()\n",
    "\n",
    "# write on job in Search bar\n",
    "search_job = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "# click using xpath function for search bar button\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/button')\n",
    "search_btn.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "85ffd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on location filter bar\n",
    "locn_filter = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "locn_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "71c1e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on location\n",
    "locn_btn = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[8]/div/label')\n",
    "locn_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e98d521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>No Of Days Ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NTT DATA GLOBAL DELIVERY SERVICES PRIVATE LIMITED</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSP CONSULTANTS INDIA PRIVATE LIMITED</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft India (R and D) Pvt Ltd</td>\n",
       "      <td>20d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HCL Technologies Ltd</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>24d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RATEGAIN TRAVEL TECHNOLOGIES LIMITED</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hanu Software Solutions Pvt Ltd</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company_Name No Of Days Ago Rating\n",
       "0  NTT DATA GLOBAL DELIVERY SERVICES PRIVATE LIMITED         7d ago    3.9\n",
       "1                           HCL Technologies Limited         9d ago    3.8\n",
       "2     Optum Global Solutions (India) Private Limited        19d ago    4.1\n",
       "3              WSP CONSULTANTS INDIA PRIVATE LIMITED         9d ago    4.2\n",
       "4                  Microsoft India (R and D) Pvt Ltd        20d ago    4.2\n",
       "5                               HCL Technologies Ltd        17d ago    3.8\n",
       "6                         Jubilant Foodworks Limited         7d ago    3.9\n",
       "7                                   HCL Technologies        24d ago    3.8\n",
       "8               RATEGAIN TRAVEL TECHNOLOGIES LIMITED         2d ago    3.8\n",
       "9                    Hanu Software Solutions Pvt Ltd         9d ago    3.7"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's extract all web elements tags\n",
    "company_tags= driver.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "ago_tags = driver.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "rating_tags = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "\n",
    "company_name = [] # empty list\n",
    "ago = []          # empty list\n",
    "rating = []       # empty list\n",
    "\n",
    "# used for loop\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "for i in ago_tags:\n",
    "    ago.append(i.text)\n",
    "ago1 = ago[0:20:2]\n",
    "for i in rating_tags:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "# Make DataFrame for first 10 rows \n",
    "data = pd.DataFrame()\n",
    "data['Company_Name'] = company_name [0:10]\n",
    "data['No Of Days Ago'] = ago1 [0:10]\n",
    "data['Rating'] = rating [0:10]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd860c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca056920",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "32d08836",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b431c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on salary button \n",
    "salary_btn = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "salary_btn.click()\n",
    "\n",
    "# write on job in profile bar\n",
    "job_profile = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "job_profile.send_keys('Data Scientist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "daee7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking using xpath function for Data_scientist\n",
    "Data_scientist = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "Data_scientist.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c24bb412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary Record</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 28 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 20.3L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZS</td>\n",
       "      <td></td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 15.3L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td></td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 25 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 14.4L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td></td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 77 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td></td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td></td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "      <td>₹ 6.9L</td>\n",
       "      <td>₹ 23.4L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company         Salary Record   Experience Average Salary  \\\n",
       "0                  Ab Inbev  based on 28 salaries  3-4 yrs exp        ₹ 20.3L   \n",
       "1                        ZS                          2 yrs exp        ₹ 15.3L   \n",
       "2                     Optum  based on 15 salaries  3-4 yrs exp        ₹ 15.1L   \n",
       "3         Fractal Analytics                        2-4 yrs exp        ₹ 15.1L   \n",
       "4           Tiger Analytics  based on 25 salaries  3-4 yrs exp        ₹ 14.4L   \n",
       "5              UnitedHealth                        2-4 yrs exp        ₹ 13.9L   \n",
       "6                   Verizon  based on 77 salaries    4 yrs exp        ₹ 12.7L   \n",
       "7  Ganit Business Solutions                          4 yrs exp        ₹ 12.4L   \n",
       "8                  Ericsson  based on 33 salaries  3-4 yrs exp        ₹ 11.9L   \n",
       "9                  Deloitte                        2-4 yrs exp        ₹ 11.7L   \n",
       "\n",
       "  Minimum Salary Maximum Salary  \n",
       "0        ₹ 15.0L        ₹ 25.5L  \n",
       "1         ₹ 9.5L        ₹ 20.0L  \n",
       "2        ₹ 11.0L        ₹ 21.3L  \n",
       "3         ₹ 9.5L        ₹ 22.0L  \n",
       "4         ₹ 8.3L        ₹ 20.0L  \n",
       "5         ₹ 8.3L        ₹ 20.5L  \n",
       "6        ₹ 10.0L        ₹ 21.0L  \n",
       "7         ₹ 8.5L        ₹ 15.0L  \n",
       "8         ₹ 5.8L        ₹ 24.0L  \n",
       "9         ₹ 6.9L        ₹ 23.4L  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's extract all web elements tags\n",
    "company_tags = driver.find_elements_by_xpath('//a[@data-v-2bae05f7]')\n",
    "salary_record_tags = driver.find_elements_by_xpath('//span[@data-v-2bae05f7]')\n",
    "experience_tags = driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "average_salary_tags = driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "minimum_salary_tags = driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "maximum_salary_tags = driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "\n",
    "\n",
    "company=[]            # empty list\n",
    "salary_record = []    # empty list \n",
    "experience = []       # empty list\n",
    "average_salary = []   # empty list\n",
    "minimum_salary = []   # empty list\n",
    "maximum_salary = []   # empty list\n",
    "\n",
    "# Using for loop to convert data to text.\n",
    "for i in company_tags:\n",
    "    company.append(i.text)\n",
    "for i in salary_record_tags:\n",
    "    salary_record.append(i.text.replace('.',''))\n",
    "for i in experience_tags:\n",
    "    experience.append(i.text.replace('Data Scientist\\n . \\n',''))\n",
    "for i in average_salary_tags:\n",
    "    average_salary.append(i.text)\n",
    "for i in minimum_salary_tags:\n",
    "    minimum_salary.append(i.text)\n",
    "m = (minimum_salary)\n",
    "minimum = m[0:20:2]\n",
    "minimum\n",
    "\n",
    "for i in maximum_salary_tags:\n",
    "    maximum_salary.append(i.text)\n",
    "ma = (maximum_salary)\n",
    "maximum = ma[1:20:2]\n",
    "maximum\n",
    "\n",
    "# Make DataFrame for first 10 rows \n",
    "Data = pd.DataFrame()\n",
    "Data['Company'] = company [0:10]\n",
    "Data['Salary Record'] = salary_record [0:10]\n",
    "Data['Experience'] = experience [0:10]\n",
    "Data['Average Salary'] = average_salary [0:10]\n",
    "Data['Minimum Salary'] = minimum [0:10]\n",
    "Data['Maximum Salary'] = maximum [0:10]\n",
    "Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
